{"cells":[{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":4877,"status":"ok","timestamp":1685873533741,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"4pUIX5bUsmOv"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["import torch\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, transforms\n","import torchvision.transforms as transforms\n","no_cuda = False\n","use_gpu = not no_cuda and torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n","print(device)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JSG_LFhO1xP-"},"source":["### Load dataset"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1454,"status":"ok","timestamp":1685873535188,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"8iNY2uJdLhD8","outputId":"f7ba6444-2b7b-485d-ae92-e258daa3f517"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train: 60000\n","Test: 10000\n"]}],"source":["batch_size = 16\n","\n","trainset = datasets.FashionMNIST('data', train=True, download=True, transform=transforms.ToTensor())\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","    \n","testset = datasets.FashionMNIST('data', train=False, transform=transforms.ToTensor())\n","testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n","\n","print('Train: {}\\nTest: {}'.format(len(trainset), len(testset)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cNRAMwV511Hg"},"source":["### Define model"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1685873535189,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"wGqH43f2sv0N"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 6, 3, padding=1)\n","        self.conv2 = nn.Conv2d(6, 16, 3, padding=0)\n","        self.relu = nn.ReLU()\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(16*6*6, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","        self.softmax = nn.Softmax(dim=1)\n","        \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","        x = self.conv2(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.relu(x)\n","        x = self.fc3(x)\n","        x = self.softmax(x)\n","        return x\n","\n","model_to_quantize = Net().to(device)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9sEA2YA9yZAC"},"source":["### Load pretrained model"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4668,"status":"ok","timestamp":1685873539854,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"wFR8ZbW-ci1q","outputId":"8c3c1dfb-87c5-4426-8f16-5ecfe96ee50e"},"outputs":[{"data":{"text/plain":["Net(\n","  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n","  (relu): ReLU()\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=576, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=84, bias=True)\n","  (fc3): Linear(in_features=84, out_features=10, bias=True)\n","  (softmax): Softmax(dim=1)\n",")"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["model_to_quantize.load_state_dict(torch.load('./mnist.pth'),strict=False)\n","model_to_quantize.eval()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"I0hXFFUFfzIl"},"source":["## Quantize"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685873539855,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"QdArc8Ni0LCp"},"outputs":[],"source":["from torch.ao.quantization import get_default_qconfig\n","from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n","from torch.ao.quantization import QConfigMapping"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZQjOFSKFyQ-J"},"source":["### set quantization config and prepare model"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685873539855,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"z4D-RaEK3Xjw"},"outputs":[],"source":["# set different quantization config\n","qconfig = get_default_qconfig('qnnpack')\n","\"\"\" (below is example of different configuration)\n","qconfig = get_default_qconfig(\"fbgemm\")\n","qconfig = torch.ao.quantization.default_qconfig\n","qconfig = torch.ao.quantization.qconfig.QConfig(\n","    activation=torch.ao.quantization.observer.HistogramObserver.with_args(\n","        qscheme=torch.per_tensor_symmetric, \n","        dtype=torch.qint8, \n","    ),\n","    weight=torch.ao.quantization.observer.PerChannelMinMaxObserver.with_args(\n","        #ch_axis=1,  \n","        qscheme=torch.per_channel_symmetric,\n","        dtype=torch.qint8,\n","        ))\n","\"\"\"\n","qconfig_mapping = QConfigMapping().set_global(qconfig)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685873539856,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"6yJhARgR3a-a","outputId":"12d40fe0-0b6a-4d65-91a7-9cb4babaec20"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\GIGABYTE\\anaconda3\\envs\\AI\\lib\\site-packages\\torch\\ao\\quantization\\fx\\utils.py:829: UserWarning: QConfig must specify a FixedQParamsObserver or a FixedQParamsFakeQuantize for fixed qparams ops, ignoring QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=False){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001F9808CD5E0>}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){'factory_kwargs': <function _add_module_to_qconfig_obs_ctr.<locals>.get_factory_kwargs_based_on_module_device at 0x000001F9808CD5E0>}).\n","Please use torch.ao.quantization.get_default_qconfig_mapping or torch.ao.quantization.get_default_qat_qconfig_mapping. Example:\n","    qconfig_mapping = get_default_qconfig_mapping(\"fbgemm\")\n","    model = prepare_fx(model, qconfig_mapping, example_inputs)\n","  warnings.warn((\"QConfig must specify a FixedQParamsObserver or a FixedQParamsFakeQuantize \"\n"]}],"source":["example_inputs = (next(iter(trainloader))[0]) # to know model input data type\n","prepared_model = prepare_fx(model_to_quantize, qconfig_mapping, example_inputs) # prepare to quantize model (fuse module (ex:CONV+BN+RELU...)，insert observer)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"U062-zl9xKJa"},"source":["### calibration (use representation data)"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":3053,"status":"ok","timestamp":1685873542905,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"0Anq--qu7gcR"},"outputs":[],"source":["def calibrate(model, device, data_loader):\n","  model.to(device)\n","  model.eval()\n","  with torch.no_grad():\n","      for data, target in data_loader:\n","        data, target = data.to(device), target.to(device) #device\n","        model(data)\n","calibrate(prepared_model, 'cpu', testloader)  # run calibration on sample data"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1685873542906,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"Psc04GKDxnmZ"},"outputs":[],"source":["quantized_model = convert_fx(prepared_model) # convert the calibrated model to a quantized model"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2rKhMe7Cf2El"},"source":["### check quantized model"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1685873542906,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"5L0J1QtsxDKb","outputId":"778b929a-02ed-4924-f202-53d63896c979"},"outputs":[{"name":"stdout","output_type":"stream","text":["Net(\n","  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n","  (relu): ReLU()\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=576, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=84, bias=True)\n","  (fc3): Linear(in_features=84, out_features=10, bias=True)\n","  (softmax): Softmax(dim=1)\n",")\n"]}],"source":["print(model_to_quantize)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685873542906,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"9yzeK1UeOExy","outputId":"0b125913-5e99-4ce7-bc58-8f5d52385df9"},"outputs":[{"name":"stdout","output_type":"stream","text":["GraphModule(\n","  (conv1): QuantizedConvReLU2d(1, 6, kernel_size=(3, 3), stride=(1, 1), scale=0.008702474646270275, zero_point=0, padding=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): QuantizedConvReLU2d(6, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.021146273240447044, zero_point=0)\n","  (fc1): QuantizedLinearReLU(in_features=576, out_features=120, scale=0.039127349853515625, zero_point=0, qscheme=torch.per_tensor_affine)\n","  (fc2): QuantizedLinearReLU(in_features=120, out_features=84, scale=0.0579749271273613, zero_point=0, qscheme=torch.per_tensor_affine)\n","  (fc3): QuantizedLinear(in_features=84, out_features=10, scale=0.22861747443675995, zero_point=175, qscheme=torch.per_tensor_affine)\n","  (softmax): Softmax(dim=1)\n",")\n","\n","\n","\n","def forward(self, x):\n","    conv1_input_scale_0 = self.conv1_input_scale_0\n","    conv1_input_zero_point_0 = self.conv1_input_zero_point_0\n","    quantize_per_tensor = torch.quantize_per_tensor(x, conv1_input_scale_0, conv1_input_zero_point_0, torch.quint8);  x = conv1_input_scale_0 = conv1_input_zero_point_0 = None\n","    conv1 = self.conv1(quantize_per_tensor);  quantize_per_tensor = None\n","    pool = self.pool(conv1);  conv1 = None\n","    conv2 = self.conv2(pool);  pool = None\n","    pool_1 = self.pool(conv2);  conv2 = None\n","    flatten = torch.flatten(pool_1, 1);  pool_1 = None\n","    fc1 = self.fc1(flatten);  flatten = None\n","    fc2 = self.fc2(fc1);  fc1 = None\n","    fc3 = self.fc3(fc2);  fc2 = None\n","    dequantize_8 = fc3.dequantize();  fc3 = None\n","    softmax = self.softmax(dequantize_8);  dequantize_8 = None\n","    return softmax\n","    \n","# To see more debug info, please use `graph_module.print_readable()`\n"]}],"source":["print(quantized_model)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qn6H7dcWf54N"},"source":["### performance analysis"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685873542907,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"zFV1z6Yj5Vkd"},"outputs":[],"source":["import os\n","def print_size_of_model(model):\n","    \"\"\" Print the size of the model.\n","    \n","    Args:\n","        model: model whose size needs to be determined\n","\n","    \"\"\"\n","    torch.save(model.state_dict(), \"temp.p\")\n","    print('Size of the model(MB):', os.path.getsize(\"temp.p\")/1e6)\n","    os.remove('temp.p')"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685873542907,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"zM6QafMp7GW3"},"outputs":[],"source":["def compare(model, device, test_loader, quantize=False):\n","  model.to(device)\n","  model.eval()\n","\n","  total = 0\n","  correct = 0\n","  with torch.no_grad():\n","    for data in test_loader:\n","      images, labels = data\n","      images, labels = images.to(device),labels.to(device)\n","      outputs = model(images)\n","      # the class with the highest energy is what we choose as prediction\n","      _, predicted = torch.max(outputs.data, 1)\n","      total += labels.size(0)\n","      correct += (predicted == labels).sum().item()\n","\n","  test_loss = 0\n","  \n","  print(\"========================================= PERFORMANCE =============================================\")\n","  print_size_of_model(model)\n","  print('\\nAccuracy: {}/{} ({:.0f}%)\\n'.format( correct, total,100. * correct / total))\n","  print(\"====================================================================================================\") "]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2411,"status":"ok","timestamp":1685873545312,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"2SkQAJmZabxM","outputId":"d980c0f2-f140-44c4-ec50-114336f49851"},"outputs":[{"name":"stdout","output_type":"stream","text":["========================================= PERFORMANCE =============================================\n","Size of the model(MB): 0.327587\n","\n","Accuracy: 9048/10000 (90%)\n","\n","====================================================================================================\n"]}],"source":["device = 'cpu'\n","compare(model=model_to_quantize, device=device, test_loader=testloader)"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3343,"status":"ok","timestamp":1685873548653,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"YqciaigbddX9","outputId":"f23ab1ac-e5d4-4e2d-ae11-77208964205a"},"outputs":[{"name":"stdout","output_type":"stream","text":["========================================= PERFORMANCE =============================================\n","Size of the model(MB): 0.088283\n","\n","Accuracy: 9024/10000 (90%)\n","\n","====================================================================================================\n"]}],"source":["device = 'cpu'\n","compare(model=quantized_model, device=device, test_loader=testloader)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Extract train weight"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1685873548654,"user":{"displayName":"沈桓敬 SHEN, HUAN-JING P76114757","userId":"12290812438432293375"},"user_tz":-480},"id":"m2awJGLrsQY4"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[-0.2616,  0.1744,  0.2791],\n","         [-0.2093, -0.2616,  0.2268],\n","         [ 0.4535, -0.3314, -0.1221]]], size=(1, 3, 3), dtype=torch.qint8,\n","       quantization_scheme=torch.per_tensor_affine, scale=0.017443126067519188,\n","       zero_point=0)\n","tensor([[[ 0.4361, -0.2093, -0.2442],\n","         [ 0.4186, -0.0174, -0.3489],\n","         [ 0.3489,  0.2268, -0.3663]]], size=(1, 3, 3), dtype=torch.qint8,\n","       quantization_scheme=torch.per_tensor_affine, scale=0.017443126067519188,\n","       zero_point=0)\n","tensor([[[-1.0117,  0.0000,  0.1221],\n","         [-2.2327, -1.0291, -0.3489],\n","         [-0.9768, -0.6454,  0.2616]]], size=(1, 3, 3), dtype=torch.qint8,\n","       quantization_scheme=torch.per_tensor_affine, scale=0.017443126067519188,\n","       zero_point=0)\n","tensor([[[ 0.4361,  0.2442, -0.2093],\n","         [ 0.5407,  0.2093,  0.1047],\n","         [ 0.0872,  0.2616,  0.5407]]], size=(1, 3, 3), dtype=torch.qint8,\n","       quantization_scheme=torch.per_tensor_affine, scale=0.017443126067519188,\n","       zero_point=0)\n","tensor([[[ 0.2442, -0.3837,  0.1570],\n","         [ 0.5582, -0.4361, -0.4710],\n","         [ 0.1047,  0.2791, -0.4361]]], size=(1, 3, 3), dtype=torch.qint8,\n","       quantization_scheme=torch.per_tensor_affine, scale=0.017443126067519188,\n","       zero_point=0)\n","tensor([[[ 0.4710,  0.4012, -0.1570],\n","         [ 0.2791,  0.2965,  0.1919],\n","         [-0.1221,  0.4535, -0.1919]]], size=(1, 3, 3), dtype=torch.qint8,\n","       quantization_scheme=torch.per_tensor_affine, scale=0.017443126067519188,\n","       zero_point=0)\n"]}],"source":["for i in quantized_model.conv1.weight():\n","  print(i)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Extract layer name"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['x', 'quantize_per_tensor', 'conv1', 'pool', 'conv2', 'pool_1', 'flatten', 'fc1', 'fc2', 'fc3', 'dequantize', 'softmax']\n"]}],"source":["import torch\n","from torchvision.models import vgg16_bn\n","from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n","\n","train_nodes, eval_nodes = get_graph_node_names(quantized_model)\n","print(eval_nodes)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Extract input activation"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["420\n"]}],"source":["import torch\n","from torchvision.models import vgg16_bn\n","from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n","\n","model = create_feature_extractor(quantized_model, [\"quantize_per_tensor\"])\n","for data in testloader:\n","      images, labels = data\n","      continue\n","#print(testloader[0])\n","image = torch.ones(1, 1, 28, 28)\n","\n","torch.set_printoptions(profile='full')\n","outputs = model(images)\n","\n","# print(outputs['quantize_per_tensor'].int_repr())\n","\n","# with open('quantize_per_tensor.txt', 'a') as f:\n","#     for k, v in outputs.items():\n","#         print(v.shape)\n","#         for i in range(len(v)):\n","#              for j in range(len(v[i])):\n","#                   for k in range(len(v[i][j])):\n","#                         for l in range(len(v[i][j][k])):\n","#                               #print(v[i][j][k][l].int_repr())\n","#                               f.write(str(bin(v[i][j][k][l].int_repr().numpy().tolist()))[2:].zfill(8))\n","#                               f.write(\"\\n\")"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[[  4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n","             4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4],\n","          [  4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n","             4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4],\n","          [  4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n","             4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4],\n","          [  4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n","             4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4],\n","          [  4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n","             4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4],\n","          [  4,   4,   4,   4,   4,   4,   4,   4,   3,   4,   4,   4,   4,   2,\n","             0,  10,   3,   3,   4,   4,   4,   4,   3,   4,   4,   4,   3,   4],\n","          [  4,   4,   4,   4,   4,   4,   4,   4,   3,   4,   4,   3,   1,   0,\n","             0,  17,  15,   3,   3,   4,   4,   4,   4,   3,   4,   4,   3,   3],\n","          [  4,   4,   4,   4,   4,   3,   4,   4,   3,   4,   4,   2,   0,   9,\n","             0,   0,  19,  22,   3,   3,   3,   4,   4,   3,   3,   3,   5,   4],\n","          [  4,   4,   4,   4,   4,   3,   3,   4,   4,   3,   2,   0,   3,  24,\n","            20,   0,   0,   4,  17,   9,   6,   3,   1,   0,   0,   0,  10,  12],\n","          [  4,   4,   4,   4,   3,   2,   0,   0,  13,   7,   4,   0,   5,  12,\n","            18,  19,   0,   0,   0,   1,   5,   6,   8,   7,   1,   0,   1,   9],\n","          [  4,   4,   3,   3,   0,   0,   9,   0,   0,  27,  15,  12,   0,   0,\n","             2,  17,  12,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   4],\n","          [  4,   4,   4,   4,   3,   0,   8,  12,   0,   0,  30,  32,   0,   0,\n","             0,   0,  10,   8,   0,   0,  26,   7,   0,  21,  12,   0,   0,   7],\n","          [  4,   4,   4,   6,  12,   0,   2,  18,   7,   0,   0,  16,  20,  17,\n","            14,   0,   0,   1,   0,   0,   0,   0,   0,  25,   6,   0,   0,   7],\n","          [  4,   4,   3,   6,  13,   0,   5,   5,  23,   8,   0,   0,   4,   0,\n","             2,   8,   0,   9,  39,  12,   0,   1,   0,   0,  16,   0,   0,   4],\n","          [  4,   4,   3,   4,  13,   0,   5,   8,   5,  18,  25,   0,   0,   0,\n","             0,   0,   0,   0,  28,   7,   0,  20,   0,   0,  36,  14,   0,   4],\n","          [  4,   4,   4,   4,  15,   0,   0,   4,  11,  19,  22,  13,   2,  13,\n","            14,   9,   6,   0,   0,   0,   0,   6,   4,   0,   0,   5,   0,   2],\n","          [  3,   3,   4,   4,  18,  10,   0,   0,   0,   0,   0,   2,   3,  14,\n","            13,   8,  27,  20,   0,   0,   0,   0,  32,   4,   0,   0,   0,   2],\n","          [  4,   4,   3,   4,  15,  12,  25,  14,   1,   0,   0,   1,   0,  10,\n","             4,   0,  11,  20,  22,  28,  22,   0,   0,   0,   0,   2,   0,   5],\n","          [  0,   7,   7,   4,  16,   0,   0,   8,   0,   3,   4,   6,   0,   0,\n","             6,   8,   0,   0,   0,   6,  40,  17,   0,   0,  11,   8,   0,   0],\n","          [  0,   0,   6,   6,  26,  17,   0,   0,   0,   0,   0,   2,   0,   0,\n","             8,  13,  10,   0,   0,   0,   4,   5,   0,   1,   0,   0,   0,   0],\n","          [ 11,   0,   0,   0,   5,  27,  12,   5,   9,   6,   7,   8,   4,   0,\n","             2,   5,  12,  12,  13,  13,  10,   7,   4,   4,   4,   1,   4,   6],\n","          [ 13,  14,   3,   1,   0,   0,   0,   0,   2,   2,   2,   2,   3,   0,\n","             0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   2,   2,   0,   0],\n","          [  6,  10,  11,  13,  15,   9,   6,   3,   3,   4,   3,   2,   3,   3,\n","             3,   4,   6,   6,   5,   5,   5,   6,   8,   7,   7,   5,   0,   0],\n","          [  4,   4,   4,   4,   6,  10,  10,   8,   8,   8,   9,   9,   9,   9,\n","             8,   7,   6,   7,   7,   7,   7,   7,   6,   4,   2,   1,   3,   4],\n","          [  4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n","             4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4],\n","          [  4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n","             4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4],\n","          [  4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n","             4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4],\n","          [  4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n","             4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4]],\n","\n","         [[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n","          [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n","          [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n","          [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n","          [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n","          [  1,   1,   1,   1,   1,   1,   1,   0,   1,   1,   1,   1,   1,   0,\n","             4,   5,   0,   1,   1,   1,   1,   0,   1,   1,   1,   0,   1,   1],\n","          [  1,   1,   1,   1,   1,   1,   1,   0,   1,   1,   0,   1,   0,   0,\n","            10,  31,   9,   0,   1,   1,   1,   1,   0,   1,   1,   0,   0,   1],\n","          [  1,   1,   1,   1,   0,   1,   1,   0,   0,   1,   0,   0,   0,   0,\n","             0,  43,  46,  14,   1,   1,   1,   1,   0,   0,   0,   2,   2,   1],\n","          [  1,   1,   1,   1,   0,   1,   1,   0,   1,   1,   0,   0,   0,   0,\n","             0,  12,  49,  40,  17,   8,   2,   0,   0,   0,   0,   8,  18,   8],\n","          [  1,   1,   1,   0,   0,   0,   0,   6,  11,   4,   0,   0,   0,   6,\n","             0,   0,  24,  36,  23,  18,  12,   8,   4,   0,   0,  10,  34,  17],\n","          [  1,   0,   1,   0,   0,   0,   0,   0,  30,  25,   0,   0,   0,  14,\n","             9,   0,   0,  15,  22,  19,  13,   7,   0,   0,   0,  12,  46,  26],\n","          [  1,   0,   0,   0,   0,   0,   6,   0,   7,  46,  21,   0,   0,   3,\n","             5,  16,  15,   0,   0,  28,  41,   3,  14,  24,   4,  17,  53,  30],\n","          [  1,   1,   0,   0,   0,   0,  15,   0,   0,  25,  37,  11,   0,  12,\n","            10,  11,  11,   0,   0,  14,  56,   6,  36,  52,   6,  11,  54,  35],\n","          [  1,   0,   1,   0,   0,   0,  17,   0,   0,   0,  14,  20,   6,  13,\n","            20,  12,  10,   0,   0,   3,  54,   0,  31,  87,  13,   0,  48,  40],\n","          [  1,   0,   1,   0,   0,   0,  23,   1,   0,   0,   0,   2,  13,   5,\n","            11,   7,   0,   4,   6,  10,  32,   5,  15, 101,  48,   0,  39,  42],\n","          [  1,   0,   1,   0,   0,   0,  20,  13,  20,  28,   5,   0,   7,   0,\n","             0,   0,   0,   0,  26,  24,  32,  14,  14,  75,  60,   3,  36,  43],\n","          [  0,   1,   1,   0,   0,   0,   0,   8,  16,  27,  18,   1,  10,  10,\n","             0,   0,   0,   0,  15,   0,   0,  27,  48,  43,  46,   9,  37,  42],\n","          [  0,   1,   1,   0,   0,   0,   0,   3,  16,  26,  12,   1,  15,  19,\n","             4,   0,   0,   2,   9,   0,   0,   9,  61,  44,  12,   8,  46,  42],\n","          [  0,   6,   3,   0,   0,   0,  14,  10,  11,   9,   7,   3,  20,  32,\n","             6,   0,   1,  17,  20,  11,   0,   0,  57,  32,   8,  14,  31,  35],\n","          [  0,   6,  11,   8,   0,   0,   6,  12,   5,   6,   5,   3,  12,  25,\n","             8,   0,   0,   4,   9,   7,   0,   0,  19,  10,   5,   9,  25,  32],\n","          [  0,   0,   7,   4,   0,   0,   1,  13,   4,   6,   5,   5,   7,  15,\n","            11,   5,   2,   3,   9,   6,   8,   8,   9,  13,  11,  19,  29,  22],\n","          [  0,   0,   0,   0,   0,   0,   0,   8,   6,   5,   4,   5,   5,   9,\n","            11,  10,   8,   7,   8,   4,   6,   3,   7,   9,   5,   6,  18,  20],\n","          [  0,   0,   0,   0,   0,   0,   0,   2,   2,   1,   0,   1,   1,   0,\n","             1,   1,   1,   0,   2,   2,   2,   1,   0,   2,   5,   8,  14,  12],\n","          [  1,   1,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   2,   2,   1,   1,   0,   1,   1,   1,   3,   4,   4,   1,   1],\n","          [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n","          [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n","          [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n","          [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1]],\n","\n","         [[ 60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,\n","            60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60],\n","          [ 60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,\n","            60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60],\n","          [ 60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,\n","            60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60],\n","          [ 60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,\n","            60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60],\n","          [ 60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,\n","            60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60],\n","          [ 60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  59,  60,  64,\n","            51,  47,  61,  60,  59,  60,  60,  60,  60,  60,  60,  60,  60,  60],\n","          [ 60,  60,  60,  60,  60,  60,  60,  60,  59,  58,  59,  58,  63,  58,\n","             0,   0,  35,  60,  58,  59,  60,  59,  59,  59,  59,  60,  60,  59],\n","          [ 60,  60,  60,  60,  60,  60,  60,  60,  59,  58,  60,  63,  50,   5,\n","             0,   0,   0,  20,  58,  58,  59,  59,  59,  59,  58,  56,  55,  58],\n","          [ 60,  60,  60,  60,  60,  60,  59,  60,  59,  57,  63,  54,  13,   0,\n","             0,   0,   0,   0,  10,  40,  55,  61,  62,  52,  36,  15,   6,  37],\n","          [ 60,  60,  60,  60,  61,  61,  59,  37,  29,  52,  62,  31,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,  16,  13,   0,   0,   0,   0,   0],\n","          [ 60,  60,  60,  60,  63,  39,   3,   0,   0,   0,  50,  32,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [ 60,  60,  60,  59,  49,   0,   0,   0,   0,   0,   0,  37,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [ 60,  60,  60,  58,  53,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [ 60,  60,  60,  61,  61,   3,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [ 60,  60,  60,  58,  59,   3,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [ 60,  60,  60,  59,  62,   9,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [ 61,  60,  59,  60,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [ 60,  59,  58,  59,  63,  11,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [ 54,  43,  53,  59,  57,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [ 49,  10,  11,  33,  34,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [ 49,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [ 61,  43,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [ 61,  63,  56,  44,  36,   7,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  15,  34],\n","          [ 60,  60,  60,  61,  61,  61,  53,  44,  41,  42,  42,  41,  38,  38,\n","            36,  35,  37,  41,  42,  43,  43,  43,  44,  44,  46,  51,  58,  60],\n","          [ 60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,\n","            60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60],\n","          [ 60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,\n","            60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60],\n","          [ 60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,\n","            60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60],\n","          [ 60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,\n","            60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60]],\n","\n","         [[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   7,\n","             4,   1,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  36,\n","            33,  19,   2,   1,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   0,   8,  19,  33,\n","            78,  85,  31,   4,   1,   1,   0,   0,   1,   2,   3,   2,   1,   0],\n","          [  0,   0,   0,   0,   0,   0,   1,   0,   0,   1,   8,  22,  25,  29,\n","            67, 108,  99,  47,  11,   3,   1,   2,   8,  15,  25,  23,  10,   3],\n","          [  0,   0,   0,   0,   1,   5,  17,  12,   5,   1,  15,  29,  38,  50,\n","            46,  70,  99,  90,  60,  40,  30,  25,  23,  27,  44,  46,  33,  13],\n","          [  0,   0,   0,   2,  15,  21,  24,  49,  34,  10,   1,  22,  55,  72,\n","            56,  51,  64,  79,  70,  58,  46,  39,  43,  49,  59,  62,  54,  23],\n","          [  0,   0,   0,   5,  19,  27,  32,  55,  78,  65,   7,  12,  46,  72,\n","            72,  71,  56,  71, 113, 107,  84,  94,  85,  74,  76,  76,  62,  24],\n","          [  0,   0,   0,   1,  14,  31,  48,  36,  72, 107,  86,  56,  49,  57,\n","            62,  66,  66,  82, 120, 151, 164, 148, 107, 101,  84,  85,  68,  29],\n","          [  0,   0,   0,   0,  17,  29,  48,  36,  37,  76, 114,  99,  87,  96,\n","            93,  88, 100,  99, 104, 157, 187, 160, 153, 139,  76,  75,  67,  34],\n","          [  0,   0,   0,   1,  17,  33,  49,  38,  43,  45,  67,  85,  93, 103,\n","           110, 112, 134, 132, 138, 166, 173, 158, 195, 164,  78,  61,  60,  36],\n","          [  0,   0,   0,   0,  19,  64, 100,  90,  72,  58,  52,  58,  75,  75,\n","            79, 101, 128, 158, 192, 183, 172, 166, 165, 154, 120,  68,  55,  38],\n","          [  1,   0,   0,   1,  12,  39,  87,  96,  90,  94,  74,  63,  63,  51,\n","            58,  75,  73, 106, 134, 140, 189, 177, 131, 143, 121,  71,  57,  37],\n","          [  0,   0,   1,   1,  16,  32,  70,  82,  96,  93,  75,  75,  68,  65,\n","            68,  68,  71,  82,  83,  89, 124, 140, 158, 121,  82,  77,  63,  36],\n","          [  7,   3,   2,   0,  19,  53,  80,  78,  80,  80,  80,  86,  89,  84,\n","            64,  66,  93, 100,  94,  82,  69, 111, 146,  92,  63,  61,  64,  38],\n","          [ 18,  25,  20,  10,   7,  34,  73,  78,  71,  75,  76,  78,  83,  76,\n","            54,  49,  60,  68,  76,  71,  62,  73,  75,  65,  63,  64,  57,  28],\n","          [  9,  29,  40,  41,  34,  35,  60,  67,  61,  64,  63,  63,  68,  68,\n","            62,  56,  55,  59,  63,  60,  65,  65,  68,  70,  67,  59,  36,  24],\n","          [  0,   8,  23,  31,  34,  43,  52,  55,  52,  52,  54,  55,  57,  60,\n","            58,  53,  52,  52,  50,  50,  50,  51,  53,  49,  41,  40,  40,  29],\n","          [  0,   0,   3,   7,  13,  23,  27,  31,  31,  30,  31,  32,  32,  33,\n","            34,  34,  34,  34,  35,  34,  33,  31,  30,  31,  30,  29,  25,  11],\n","          [  0,   0,   0,   0,   0,   0,   4,   9,  10,  10,   9,  11,  12,  12,\n","            13,  14,  12,  10,  10,   9,   9,   9,   9,   9,   8,   5,   1,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n","\n","         [[ 40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,\n","            40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40],\n","          [ 40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,\n","            40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40],\n","          [ 40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,\n","            40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40],\n","          [ 40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,\n","            40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40],\n","          [ 40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,\n","            40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40],\n","          [ 40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  41,  40,  35,\n","            44,  42,  40,  41,  41,  40,  40,  40,  40,  41,  41,  40,  41,  41],\n","          [ 40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  33,  15,\n","            41,  61,  43,  40,  41,  41,  40,  40,  40,  41,  41,  40,  40,  41],\n","          [ 40,  40,  40,  40,  40,  41,  41,  40,  40,  41,  40,  34,  26,   2,\n","             0,  70,  74,  44,  40,  41,  40,  41,  40,  39,  40,  41,  41,  41],\n","          [ 40,  40,  40,  40,  40,  40,  41,  40,  40,  41,  35,  24,  25,  25,\n","             0,   0,  70,  73,  47,  44,  41,  39,  35,  34,  31,  42,  51,  43],\n","          [ 40,  40,  40,  40,  40,  37,  32,  45,  45,  41,  23,  13,  25,  35,\n","            35,   0,  12,  49,  53,  48,  43,  39,  34,  25,  16,  31,  61,  54],\n","          [ 40,  40,  40,  39,  29,  34,  26,  13,  68,  52,  31,   0,  20,  37,\n","            34,  33,  20,  21,  29,  35,  35,  32,  28,  29,  19,  28,  63,  60],\n","          [ 40,  40,  40,  36,  18,  21,  41,   1,  13,  84,  58,  18,   1,  25,\n","            23,  38,  36,  19,   2,  48,  48,  18,  34,  28,  23,  29,  69,  61],\n","          [ 40,  41,  40,  37,  17,  18,  42,  35,   0,  24,  64,  47,  15,  28,\n","            21,  29,  37,   8,   0,   0,  52,   1,  28,  56,  25,  23,  69,  66],\n","          [ 40,  40,  41,  40,  16,  20,  39,  37,  17,   0,   4,  35,  20,  35,\n","            47,  28,  19,  13,   0,   0,  29,   0,  18,  96,  34,  13,  59,  70],\n","          [ 40,  40,  40,  40,  13,  14,  50,  29,  27,  31,   4,  12,  28,   3,\n","            15,  14,   0,  10,  14,   9,  32,  10,   0,  97,  61,  12,  52,  72],\n","          [ 40,  40,  40,  41,  11,   0,  41,  32,  33,  41,  43,  18,  32,  23,\n","             8,   7,   0,   0,  21,   8,  14,  13,   0,  37,  82,  30,  45,  73],\n","          [ 40,  41,  41,  40,  15,   0,   0,  14,  28,  47,  43,  24,  28,  33,\n","            24,  25,  10,   0,  10,   0,   0,  28,  45,  32,  55,  30,  50,  71],\n","          [ 40,  40,  41,  39,  17,  11,  25,  25,  26,  33,  28,  18,  37,  45,\n","            27,  19,  27,  33,  36,  19,   0,   0,  67,  56,  25,  26,  56,  71],\n","          [ 41,  44,  41,  40,  10,   0,  37,  26,  28,  27,  25,  20,  28,  46,\n","            28,   9,   9,  28,  33,  38,  20,   0,  46,  43,  27,  30,  44,  73],\n","          [ 22,  43,  45,  44,  27,   0,  19,  31,  21,  24,  23,  22,  22,  42,\n","            35,  24,  17,  17,  23,  24,  31,  17,  33,  32,  36,  42,  44,  56],\n","          [ 20,  17,  37,  33,  43,  21,  21,  38,  29,  31,  30,  30,  27,  38,\n","            40,  39,  38,  35,  39,  33,  33,  33,  36,  38,  28,  32,  49,  51],\n","          [ 39,  23,  27,  24,  21,  28,  27,  34,  32,  30,  31,  32,  29,  28,\n","            30,  27,  26,  25,  30,  27,  30,  25,  24,  28,  29,  34,  49,  57],\n","          [ 42,  41,  38,  41,  32,  29,  29,  32,  34,  33,  31,  30,  32,  30,\n","            33,  34,  36,  34,  35,  35,  35,  36,  36,  40,  44,  44,  41,  47],\n","          [ 40,  40,  41,  41,  41,  40,  39,  40,  41,  41,  41,  40,  41,  41,\n","            40,  41,  42,  41,  41,  41,  41,  41,  40,  41,  41,  42,  41,  40],\n","          [ 40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,\n","            40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40],\n","          [ 40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,\n","            40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40],\n","          [ 40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,\n","            40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40],\n","          [ 40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,\n","            40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40]],\n","\n","         [[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","            22,   9,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   5,  16,\n","            31,  51,  16,   0,   1,   0,   0,   0,   0,   0,   0,   1,   1,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   3,  13,  20,\n","            58,  76,  58,  20,   2,   1,   0,   0,   0,   3,   3,  10,   6,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   9,   1,   0,   0,  12,  29,  31,\n","            37,  68,  86,  53,  25,  11,   6,   5,   8,  11,  17,  32,  23,   3],\n","          [  0,   0,   0,   0,   0,   9,  11,   7,  33,   0,   2,  10,  43,  46,\n","            41,  34,  54,  68,  58,  41,  30,  24,  19,  28,  33,  53,  45,  13],\n","          [  0,   0,   0,   0,   4,  20,  22,  32,  42,  39,   0,   5,  39,  50,\n","            46,  49,  44,  34,  46,  75,  45,  30,  60,  42,  44,  59,  54,  13],\n","          [  0,   0,   0,   1,   0,  30,  35,  27,  55,  65,  38,  10,  27,  50,\n","            53,  54,  47,  43,  67,  99,  83,  66,  89,  62,  55,  68,  61,  15],\n","          [  0,   0,   0,   0,   0,  33,  33,  24,  33,  68,  78,  65,  43,  52,\n","            53,  50,  51,  51,  72, 135, 146, 106, 133, 108,  54,  63,  66,  19],\n","          [  0,   0,   0,   0,   0,  32,  36,  24,  25,  44,  63,  80,  84,  77,\n","            76,  63,  63,  90,  87, 119, 131, 115, 132, 134,  43,  40,  63,  21],\n","          [  0,   0,   0,   0,   0,  30,  49,  34,  47,  37,  32,  51,  57,  62,\n","            77,  82,  94, 122, 131, 130, 120, 104, 137, 127,  70,  46,  57,  23],\n","          [  0,   0,   0,   0,   0,  44,  70,  74,  64,  63,  46,  37,  50,  42,\n","            43,  62,  76, 110, 131, 114, 120, 155, 120, 119, 100,  53,  57,  23],\n","          [  0,   0,   0,   0,   0,  29,  60,  76,  87,  76,  54,  48,  54,  45,\n","            44,  45,  47,  65,  75,  87, 107, 137, 121,  93,  58,  55,  61,  21],\n","          [  4,   2,   0,   1,   0,  33,  54,  46,  53,  50,  52,  56,  66,  56,\n","            38,  43,  60,  66,  55,  46,  52, 100, 121,  67,  52,  56,  52,  29],\n","          [  3,  13,   5,   3,   0,  32,  65,  60,  58,  59,  60,  62,  69,  63,\n","            46,  50,  63,  74,  71,  68,  54,  71,  77,  59,  53,  50,  53,  26],\n","          [  9,  21,  23,  12,  11,  22,  51,  56,  51,  54,  55,  56,  58,  56,\n","            43,  39,  37,  44,  48,  47,  51,  48,  47,  46,  45,  45,  33,  15],\n","          [  0,  16,  29,  33,  30,  31,  40,  42,  39,  39,  39,  40,  42,  44,\n","            42,  38,  35,  36,  34,  34,  36,  38,  43,  40,  38,  38,  37,  25],\n","          [  0,   0,   8,  13,  22,  33,  35,  36,  35,  34,  35,  36,  36,  37,\n","            38,  38,  39,  40,  42,  41,  39,  38,  37,  38,  37,  35,  30,  12],\n","          [  0,   0,   0,   0,   0,   2,   8,  14,  15,  15,  15,  17,  18,  19,\n","            20,  20,  17,  15,  15,  14,  14,  13,  13,  13,  10,   5,   1,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n","          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]]],\n","       dtype=torch.uint8)\n","(1, 6, 28, 28)\n"]}],"source":["import torch\n","\n","\n","import torch\n","from torchvision.models import vgg16_bn\n","from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n","\n","model = create_feature_extractor(quantized_model, [\"conv1\"])\n","for data in testloader:\n","      images, labels = data\n","      continue\n","\n","image = torch.ones(1, 1, 28, 28)\n","torch.set_printoptions(profile='full')\n","outputs = model(images)\n","#print(outputs.items())\n","outputs = outputs['conv1'].int_repr()\n","print(outputs)\n","\n","import pandas as pd\n","import numpy as np\n","outputs = outputs.numpy()\n","print(outputs.shape)\n","\n","\n","for i in range(1):\n","    for j in range(6):\n","        x_df = pd.DataFrame(outputs[i][j])\n","        x_df.to_csv('conv1.csv', mode='a', header=True, index=True)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":0}
